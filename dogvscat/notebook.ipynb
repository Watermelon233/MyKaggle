{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'test.zip', 'train', 'train.zip']\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import shutil  \n",
    "import torch  \n",
    "import collections  \n",
    "from torchvision import transforms,datasets  \n",
    "from __future__ import print_function, division  \n",
    "import os  \n",
    "import torch  \n",
    "import pylab  \n",
    "import pandas as pd  \n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F  \n",
    "\n",
    "from torch.autograd import Variable  \n",
    "from skimage import io, transform  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from torchvision import transforms, utils  \n",
    "import math  \n",
    "from PIL import Image \n",
    "\n",
    "# Ignore warnings  \n",
    "import warnings  \n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "  \n",
    "plt.ion()   # interactive mode  \n",
    "import os\n",
    "print(os.listdir(\"./data\"))\n",
    "from torch.utils.data import DataLoader\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "d32a7426-68e8-40aa-a4ad-b0a9eec4eb71",
    "_uuid": "e71faec672986a723990bf358d83f315861f29b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"./data/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "78cf3055-3676-47e1-a7bd-099597434d54",
    "_uuid": "0253952fc250669d4d4f20572236a17069430070"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import  Image\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from torchvision import  transforms as T\n",
    "\n",
    "\n",
    "class DogCat(data.Dataset):\n",
    "    \n",
    "    def __init__(self,root,transforms=None,train=True,test=False):\n",
    "        '''\n",
    "        主要目标： 获取所有图片的地址，并根据训练，验证，测试划分数据\n",
    "        '''\n",
    "        self.test = test\n",
    "        self.transforms =transforms\n",
    "        imgs = [os.path.join(root,img) for img in os.listdir(root)] \n",
    "\n",
    "        # test1: data/test1/8973.jpg\n",
    "        # train: data/train/cat.10004.jpg \n",
    "        if self.test:\n",
    "            imgs = sorted(imgs,key=lambda x:int(x.split('.')[-2].split('/')[-1]))\n",
    "        else:\n",
    "            imgs = sorted(imgs,key=lambda x:int(x.split('.')[-2]))\n",
    "            \n",
    "        imgs_num = len(imgs)\n",
    "\n",
    "        if self.test:\n",
    "            self.imgs = imgs\n",
    "        elif train:\n",
    "            self.imgs = imgs[:int(0.7*imgs_num)]\n",
    "        else :\n",
    "            self.imgs = imgs[int(0.7*imgs_num):]\n",
    "            \n",
    "    \n",
    "        if transforms is None:\n",
    "            normalize = T.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                                     std = [0.229, 0.224, 0.225])\n",
    "\n",
    "            if self.test or not train: \n",
    "                self.transforms = T.Compose([\n",
    "                    T.Scale(224),\n",
    "                    T.CenterCrop(224),\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                    ]) \n",
    "            else :\n",
    "                self.transforms = T.Compose([\n",
    "                    T.Scale(256),\n",
    "                    T.RandomSizedCrop(224),\n",
    "                    T.RandomHorizontalFlip(),\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                    ]) \n",
    "                \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        '''\n",
    "        一次返回一张图片的数据\n",
    "        '''\n",
    "        img_path = self.imgs[index]\n",
    "        if self.test: label = int(self.imgs[index].split('.')[-2].split('/')[-1])\n",
    "        else: label = 1 if 'dog' in img_path.split('/')[-1] else 0\n",
    "        data = Image.open(img_path)\n",
    "        data = self.transforms(data)\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "61d11639-9f1f-49b5-a403-029ca22a3065",
    "_uuid": "62947444c48a13d7a57c16ee791fc6b966348747"
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([  \n",
    "    transforms.Resize(84),    \n",
    "    transforms.CenterCrop(84),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean = [0.5,0.5,0.5],std = [0.5,0.5,0.5])  \n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "4519b8cf-89d0-4fdd-b9cf-bd3b71da341d",
    "_uuid": "4baea8b75477e7bb44bbc3ce7df4533f756d86c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500 7500 12500\n"
     ]
    }
   ],
   "source": [
    "dogcat = DogCat(\"./data/train/\",train=True)\n",
    "test = DogCat(\"./data/train/\",train=False,test=False)\n",
    "pred = DogCat(\"./data/test/\",test=True,train=False)\n",
    "print(len(dogcat),len(test),len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "9a4e5ec5-1cec-4826-9522-e8c51f8e9b70",
    "_uuid": "382b086c482956814a63be716932d4620bd67f8b"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_dataloader = DataLoader(dogcat,batch_size=64,shuffle = True)\n",
    "valid_dataloader  = DataLoader(test,batch_size=64,shuffle = True)\n",
    "pred_dataloader = DataLoader(pred,batch_size=64,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "a31c907d-1977-4d61-a620-6b0916c3bed3",
    "_uuid": "5038a5fa8f0d23745b520b98ee3d101c1c557322"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(Net,self).__init__()  \n",
    "          \n",
    "        self.conv1 = nn.Conv2d(3,6,5)  \n",
    "        self.pool = nn.MaxPool2d(2,2)  \n",
    "        self.conv2 = nn.Conv2d(6,16,5)  \n",
    "        self.fc1 = nn.Linear(16 * 18 * 18,800)  \n",
    "        self.fc2 = nn.Linear(800,120)  \n",
    "        self.fc3 = nn.Linear(120,2)  \n",
    "          \n",
    "    def forward(self,x):  \n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1,16 * 18 * 18)  \n",
    "        x = F.relu(self.fc1(x))  \n",
    "        x = F.relu(self.fc2(x))  \n",
    "        x = self.fc3(x)  \n",
    "          \n",
    "        return x  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "937e9d07-9bb2-4d0b-9baf-09f9b0542482",
    "_uuid": "3253aae766c5599695e278cf9100d8f87ff4b187"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim  \n",
    "import datetime\n",
    "from torchvision import models\n",
    "\n",
    "net = Net()   \n",
    "net = net.cuda()\n",
    "\n",
    "cirterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(net.parameters(),lr=0.0001, betas=(0.9, 0.99))  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "29d5bd22-21ef-48f3-b9ff-d6f46e5427e7",
    "_uuid": "4c5dc8e7075bf98b7ff2c934e15e32f3926790ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\win/.torch\\models\\vgg16-397923af.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "net  = models.vgg16(pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "908d4afe-7853-4635-8c81-62b008f9d27f",
    "_uuid": "e2d252b553c580de9cc2ac374162a6c3cbd26fe4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1   200] loss: 0.691, Time:\n",
      "2018-04-26 00:42:18\n",
      "[2   200] loss: 0.691, Time:\n",
      "2018-04-26 00:44:56\n",
      "[3   200] loss: 0.691, Time:\n",
      "2018-04-26 00:47:33\n",
      "[4   200] loss: 0.691, Time:\n",
      "2018-04-26 00:50:11\n",
      "[5   200] loss: 0.691, Time:\n",
      "2018-04-26 00:52:49\n",
      "[6   200] loss: 0.691, Time:\n",
      "2018-04-26 00:55:27\n",
      "[7   200] loss: 0.691, Time:\n",
      "2018-04-26 00:58:05\n",
      "[8   200] loss: 0.691, Time:\n",
      "2018-04-26 01:00:43\n",
      "[9   200] loss: 0.691, Time:\n",
      "2018-04-26 01:03:22\n",
      "[10   200] loss: 0.691, Time:\n",
      "2018-04-26 01:06:00\n",
      "[11   200] loss: 0.691, Time:\n",
      "2018-04-26 01:08:38\n",
      "[12   200] loss: 0.691, Time:\n",
      "2018-04-26 01:11:16\n",
      "[13   200] loss: 0.691, Time:\n",
      "2018-04-26 01:13:54\n",
      "[14   200] loss: 0.691, Time:\n",
      "2018-04-26 01:16:32\n",
      "[15   200] loss: 0.691, Time:\n",
      "2018-04-26 01:19:10\n",
      "[16   200] loss: 0.691, Time:\n",
      "2018-04-26 01:21:48\n",
      "[17   200] loss: 0.691, Time:\n",
      "2018-04-26 01:24:26\n",
      "[18   200] loss: 0.691, Time:\n",
      "2018-04-26 01:27:05\n",
      "[19   200] loss: 0.691, Time:\n",
      "2018-04-26 01:29:43\n",
      "[20   200] loss: 0.691, Time:\n",
      "2018-04-26 01:32:21\n",
      "[21   200] loss: 0.691, Time:\n",
      "2018-04-26 01:34:59\n",
      "[22   200] loss: 0.691, Time:\n",
      "2018-04-26 01:37:38\n",
      "[23   200] loss: 0.691, Time:\n",
      "2018-04-26 01:40:16\n",
      "[24   200] loss: 0.691, Time:\n",
      "2018-04-26 01:42:54\n",
      "[25   200] loss: 0.691, Time:\n",
      "2018-04-26 01:45:32\n",
      "[26   200] loss: 0.691, Time:\n",
      "2018-04-26 01:48:11\n",
      "[27   200] loss: 0.691, Time:\n",
      "2018-04-26 01:50:49\n",
      "[28   200] loss: 0.691, Time:\n",
      "2018-04-26 01:53:27\n",
      "[29   200] loss: 0.691, Time:\n",
      "2018-04-26 01:56:05\n",
      "[30   200] loss: 0.691, Time:\n",
      "2018-04-26 01:58:44\n",
      "[31   200] loss: 0.691, Time:\n",
      "2018-04-26 02:01:22\n",
      "[32   200] loss: 0.691, Time:\n",
      "2018-04-26 02:04:00\n",
      "[33   200] loss: 0.691, Time:\n",
      "2018-04-26 02:06:39\n",
      "[34   200] loss: 0.691, Time:\n",
      "2018-04-26 02:09:17\n",
      "[35   200] loss: 0.691, Time:\n",
      "2018-04-26 02:11:55\n",
      "[36   200] loss: 0.691, Time:\n",
      "2018-04-26 02:14:33\n",
      "[37   200] loss: 0.691, Time:\n",
      "2018-04-26 02:17:12\n",
      "[38   200] loss: 0.691, Time:\n",
      "2018-04-26 02:19:50\n",
      "[39   200] loss: 0.691, Time:\n",
      "2018-04-26 02:22:28\n",
      "[40   200] loss: 0.691, Time:\n",
      "2018-04-26 02:25:06\n",
      "[41   200] loss: 0.691, Time:\n",
      "2018-04-26 02:27:45\n",
      "[42   200] loss: 0.691, Time:\n",
      "2018-04-26 02:30:23\n",
      "[43   200] loss: 0.691, Time:\n",
      "2018-04-26 02:33:01\n",
      "[44   200] loss: 0.691, Time:\n",
      "2018-04-26 02:35:39\n",
      "[45   200] loss: 0.691, Time:\n",
      "2018-04-26 02:38:17\n",
      "[46   200] loss: 0.691, Time:\n",
      "2018-04-26 02:40:56\n",
      "[47   200] loss: 0.691, Time:\n",
      "2018-04-26 02:43:34\n",
      "[48   200] loss: 0.691, Time:\n",
      "2018-04-26 02:46:12\n",
      "[49   200] loss: 0.691, Time:\n",
      "2018-04-26 02:48:50\n",
      "[50   200] loss: 0.691, Time:\n",
      "2018-04-26 02:51:28\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(50):  \n",
    "    running_loss = 0.0  \n",
    "      \n",
    "    for i,data in enumerate(train_dataloader):  \n",
    "        inputs,labels = data  \n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        #print(type(inputs))\n",
    "        #print(type(labels))\n",
    "        inputs,labels = Variable(inputs),Variable(labels) \n",
    "        #print(data[1])\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = net(inputs)  \n",
    "        loss = cirterion(outputs,labels)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "          \n",
    "        running_loss += loss.data[0]  \n",
    "          \n",
    "        if i % 200 == 199:  \n",
    "            nowTime=datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')#现在\n",
    "            print('[%d %5d] loss: %.3f, Time:' % (epoch + 1,i + 1,running_loss / 2000)) \n",
    "            print(nowTime)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "print('finished training!')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "04a4069f-2c2f-4e8d-87e3-ea09b34da7bf",
    "_uuid": "9377c0a8603e4b80e19d8974a9f14893aea41f1b"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at c:\\users\\administrator\\downloads\\new-builder\\win-wheel\\pytorch\\aten\\src\\thc\\generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-cc4adef0b7a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 301\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at c:\\users\\administrator\\downloads\\new-builder\\win-wheel\\pytorch\\aten\\src\\thc\\generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "correct = 0  \n",
    "total = 0  \n",
    "  \n",
    "for data in valid_dataloader:  \n",
    "    images,labels = data  \n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    outputs = net(Variable(images)).cuda()  \n",
    "    _,predicted = torch.max(outputs.data,1)  \n",
    "    total += labels.size(0)  \n",
    "    correct += (predicted == labels).sum()  \n",
    "  \n",
    "\n",
    "print('Accuracy of the network on the 5000 test images: %d %%' % (100 * correct / total))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "536ffed6-7b0a-418a-9c2b-7210b6be7c9f",
    "_uuid": "56e473d8c76224b4f83850b9d5a5c657c118efed",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
